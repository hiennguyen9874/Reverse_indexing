{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599555210743",
   "display_name": "Python 3.6.9 64-bit ('reid': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import yaml\n",
    "import torch\n",
    "import shutil\n",
    "import subprocess\n",
    "import collections\n",
    "import pkg_resources\n",
    "import collections.abc\n",
    "\n",
    "import torch\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "from data import PA_100K, Peta\n",
    "from database import *\n",
    "from models import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Connecting...')\n",
    "database = Database_reid(host='52.230.123.142', port=6379, db=10, password='abcxyz123')\n",
    "print('Connected!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasource = Peta('/datasets', True, True, True)\n",
    "attribute_name = datasource.get_attribute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = read_config('config.yml', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = config['n_gpu'] > 0 and torch.cuda.is_available()\n",
    "device = torch.device('cuda:0' if use_gpu else 'cpu')\n",
    "map_location = \"cuda:0\" if use_gpu else torch.device('cpu')\n",
    "\n",
    "model, _ = build_model(config, num_classes=len(attribute_name))\n",
    "checkpoint = torch.load(config['resume'], map_location=map_location)\n",
    "\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "image_processing = A.Compose([\n",
    "    A.Resize(config['data']['size'][0], config['data']['size'][1]),\n",
    "    A.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225],\n",
    "    ),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imread(path):\n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return image\n",
    "\n",
    "def cv2_to_bytes(origin_image):\n",
    "    pil_image = Image.fromarray(origin_image)\n",
    "    im_file = io.BytesIO()\n",
    "    pil_image.save(im_file, format=\"JPEG\")\n",
    "    image_bytes = im_file.getvalue()\n",
    "    return image_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, transform):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img_path, label = self.data[index]\n",
    "        img = imread(img_path)\n",
    "        result = self.transform(image=img)\n",
    "        return result['image'], label, img_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "dataset = ImageDataset(data=datasource.get_data('train'), transform=image_processing)\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_data = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (image, labels, img_path) in tqdm(enumerate(dataloader)):\n",
    "        image = image.to(device)\n",
    "\n",
    "        out = model(image)\n",
    "        out = torch.sigmoid(out)\n",
    "\n",
    "        out[out>0.7]=2\n",
    "        out[out<0.3]=0\n",
    "        out[(out >= 0.3) & (out <= 0.7)] = 1\n",
    "        out = out.type(torch.IntTensor).tolist()\n",
    "\n",
    "        for idx in range(len(img_path)):\n",
    "            all_data.append((img_path[idx], out[idx]))\n",
    "        if batch_idx == 10:\n",
    "            break\n",
    "# all_data\n",
    "num_one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "database.remove_all()\n",
    "time_insert = database.insert(data=all_data, attribute_label=attribute_name, tag='pre_insert')\n",
    "print(f'time insert data: {time_insert}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_dict = {'personalMale': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_key(query_dict, tag=None):\n",
    "    r\"\"\" Return query string from dict.\n",
    "    \"\"\"\n",
    "    query_key = ''\n",
    "    for attribute in attribute_name:\n",
    "        query_key += attribute + '-'\n",
    "        if attribute in query_dict.keys():\n",
    "            query_key += str(query_dict[attribute])\n",
    "        else:\n",
    "            query_key += '?'\n",
    "        query_key += '_'\n",
    "    if tag != None:\n",
    "        query_key += 'tag-'+ tag + '_'\n",
    "    query_key = query_key + '*'\n",
    "    return query_key\n",
    "\n",
    "query_str = get_query_key(query_dict)\n",
    "query_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_path = database.query_all(query_str)\n",
    "all_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "list_path = all_path[:10]\n",
    "\n",
    "img = np.concatenate([Image.open(x).resize((64, 128)) for x in list_path], axis=1)\n",
    "plt.figure(figsize=(40, 20*5))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}